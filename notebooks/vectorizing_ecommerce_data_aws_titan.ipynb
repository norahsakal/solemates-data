{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "076d038a-5c40-4bec-8761-d3c089de328c",
   "metadata": {},
   "source": [
    "![Cover image](https://d1fiydes8a4qgo.cloudfront.net/blog/2025/february/1/linkedin_card.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9f05b5c-6c6c-4383-b3f9-58fc5b7e5a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import base64\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "from IPython.display import display, Image, HTML\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97d7a184-dab4-4284-a598-37f857265d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move up a directory if needed\n",
    "if not os.path.exists('data/solemates_shoe_directory.csv'):\n",
    "    os.chdir('..')\n",
    "    assert os.path.exists('data/solemates_shoe_directory.csv'), \"Data directory not found.\"\n",
    "\n",
    "# Define paths dynamically\n",
    "DATA_PATH = \"data/solemates_shoe_directory.csv\"\n",
    "IMAGE_PATH = \"data/footwear\"  # Adjust if images are stored elsewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca7ad63-938c-493f-bf25-31d233a1610d",
   "metadata": {},
   "source": [
    "# Load shoe data\n",
    "Let's start by reading the SoleMates shoe dataset. This dataset contains detailed product information, such as shoe colors and heel heights, which we'll transform into embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e81cd0a-d878-4274-9065-23d0a0bf4a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>product_type</th>\n",
       "      <th>color</th>\n",
       "      <th>usage</th>\n",
       "      <th>color_details</th>\n",
       "      <th>heel_height</th>\n",
       "      <th>heel_type</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_id</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Puma men future cat remix sf black casual shoes</td>\n",
       "      <td>men</td>\n",
       "      <td>casual shoes</td>\n",
       "      <td>black</td>\n",
       "      <td>casual</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>puma</td>\n",
       "      <td>1</td>\n",
       "      <td>1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buckaroo men flores black formal shoes</td>\n",
       "      <td>men</td>\n",
       "      <td>formal shoes</td>\n",
       "      <td>black</td>\n",
       "      <td>formal</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155</td>\n",
       "      <td>buckaroo</td>\n",
       "      <td>2</td>\n",
       "      <td>2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gas men europa white shoes</td>\n",
       "      <td>men</td>\n",
       "      <td>casual shoes</td>\n",
       "      <td>white</td>\n",
       "      <td>casual</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "      <td>gas</td>\n",
       "      <td>3</td>\n",
       "      <td>3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike men's incinerate msl white blue shoe</td>\n",
       "      <td>men</td>\n",
       "      <td>sports shoes</td>\n",
       "      <td>white</td>\n",
       "      <td>sports</td>\n",
       "      <td>[blue]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125</td>\n",
       "      <td>nike</td>\n",
       "      <td>4</td>\n",
       "      <td>4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clarks men hang work leather black formal shoes</td>\n",
       "      <td>men</td>\n",
       "      <td>formal shoes</td>\n",
       "      <td>black</td>\n",
       "      <td>formal</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>clarks</td>\n",
       "      <td>5</td>\n",
       "      <td>5.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     product_title gender  product_type  \\\n",
       "0  Puma men future cat remix sf black casual shoes    men  casual shoes   \n",
       "1           Buckaroo men flores black formal shoes    men  formal shoes   \n",
       "2                       Gas men europa white shoes    men  casual shoes   \n",
       "3        Nike men's incinerate msl white blue shoe    men  sports shoes   \n",
       "4  Clarks men hang work leather black formal shoes    men  formal shoes   \n",
       "\n",
       "   color   usage color_details  heel_height heel_type  price_usd     brand  \\\n",
       "0  black  casual            []          NaN       NaN        220      puma   \n",
       "1  black  formal            []          NaN       NaN        155  buckaroo   \n",
       "2  white  casual            []          NaN       NaN        105       gas   \n",
       "3  white  sports        [blue]          NaN       NaN        125      nike   \n",
       "4  black  formal            []          NaN       NaN        220    clarks   \n",
       "\n",
       "   product_id  image  \n",
       "0           1  1.jpg  \n",
       "1           2  2.jpg  \n",
       "2           3  3.jpg  \n",
       "3           4  4.jpg  \n",
       "4           5  5.jpg  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the SoleMates shoe dataset\n",
    "df_shoes = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Convert 'color_details' from string representation of a list to an actual list\n",
    "df_shoes['color_details'] = df_shoes['color_details'].apply(ast.literal_eval)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df_shoes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ada85-cfe8-4460-b538-0a4c7b10c3f7",
   "metadata": {},
   "source": [
    "# Visualize shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28b3710a-c12b-4b66-9c4c-3cc8e518bb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center;\"><img src=\"data/footwear/1.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/2.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/3.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/4.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/5.jpg\" style=\"width:100px; margin-right:10px;\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "width = 100\n",
    "images_html = \"\"\n",
    "for img_file in df_shoes.head()['image']:\n",
    "    img_path = os.path.join(IMAGE_PATH, img_file)\n",
    "    # Add each image as an HTML <img> tag\n",
    "    images_html += f'<img src=\"{img_path}\" style=\"width:{width}px; margin-right:10px;\">'\n",
    "# Display all images in a row using HTML\n",
    "display(HTML(f'<div style=\"display: flex; align-items: center;\">{images_html}</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d0563f-3a39-4d6d-a3cb-faf3a0c112a0",
   "metadata": {},
   "source": [
    "# Cost of vectorization and pre-embedded dataset\n",
    "Vectorizing datasets with AWS Bedrock and the Titan multimodal model involves costs based on the number of input tokens and images:\n",
    "\n",
    "Text embeddings: $0.0008 per 1,000 input tokens\n",
    "\n",
    "Image embeddings: $0.00006 per image\n",
    "\n",
    "The provided SoleMates dataset is small, containing just 1306 pairs of shoes, making it affordable to vectorize. For this dataset, I calculated the total cost of vectorization and summarized the token counts below:\n",
    "\n",
    "Token Count: 12746 tokens\n",
    "Images: 1306\n",
    "Total Cost: $0.0885568\n",
    "If you prefer not to generate embeddings yourself or don't have access to AWS, you can use a pre-embedded dataset that I've prepared as a CSV file. This file includes all embeddings and token counts, allowing you to follow the guide without incurring additional costs. However, for hands-on experience, I recommend running the embedding process to understand the workflow.\n",
    "\n",
    "To load the pre-embedded dataset, use the following code:\n",
    "```python\n",
    "# Load pre-embedded dataset\n",
    "df_shoes_with_embeddings = pd.read_csv('../data/solemates_shoe_directory_with_embeddings_token_count.csv')\n",
    "\n",
    "# Convert string representations to actual lists\n",
    "df_shoes_with_embeddings['titan_embedding'] = df_shoes_with_embeddings['titan_embedding'].apply(ast.literal_eval)\n",
    "```\n",
    "This step is entirely optional and designed to accommodate various levels of access and resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd7c43-0b54-47a2-8871-57fb3326957d",
   "metadata": {},
   "source": [
    "# Set up AWS Bedrock client\n",
    "You'll need access to Amazon Bedrock foundation models.\n",
    "\n",
    "## What is AWS Bedrock?\n",
    "Amazon Bedrock is a fully managed service offering high-performing foundation models (FMs) for building generative AI applications.\n",
    "\n",
    "Bedrock is serverless and offers multiple foundational models to choose between.\n",
    "\n",
    "## What is AWS Titan?\n",
    "Amazon Titan Multimodal Embeddings G1 model is a multimodal embedding model that converts both product texts and images into vectors.\n",
    "\n",
    "[Learn more about AWS Titan G1 ↗](https://docs.aws.amazon.com/bedrock/latest/userguide/titan-multiemb-models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a186cb5c-1331-48ce-a98e-e55dfa8ef998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your AWS profile\n",
    "# Replace AWS_PROFILE with the name of your AWS CLI profile\n",
    "# To use your default AWS profile, leave 'aws_profile' as None\n",
    "aws_profile = os.environ.get('AWS_PROFILE')\n",
    "\n",
    "# Specify the AWS region where Bedrock is available\n",
    "aws_region_name = \"us-east-1\"\n",
    "\n",
    "try:\n",
    "    # Set the default session for the specified profile\n",
    "    if aws_profile:\n",
    "        boto3.setup_default_session(profile_name=aws_profile)\n",
    "    else:\n",
    "        boto3.setup_default_session()  # Use default AWS profile if none is specified\n",
    "\n",
    "    # Initialize the Bedrock runtime client\n",
    "    bedrock_runtime = boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=aws_region_name\n",
    "    )\n",
    "except NoCredentialsError:\n",
    "    print(\"AWS credentials not found. Please configure your AWS profile.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03ef948-0980-4747-b8db-a3003954d3d5",
   "metadata": {},
   "source": [
    "# Generate embeddings for product data\n",
    "To prepare our product data for the vector database, we'll generate embeddings for each product using AWS Titan. These embeddings combine image and text data to represent each product in a format suitable for search and recommendation systems.\n",
    "\n",
    "Before generating embeddings, we'll initialize two new columns in the dataset:\n",
    "\n",
    "- **titan_embedding:** To store the embedding vectors\n",
    "- **token_count:** To store the token count for each product title\n",
    "\n",
    "Then, we'll define a function to generate embeddings and apply it to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e8a524-6dcc-4877-895b-1a6f76231d94",
   "metadata": {},
   "source": [
    "# Initialize columns for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6d779f9-adf2-4781-b5b9-3d4515412adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize columns to store embeddings and token counts\n",
    "df_shoes['titan_embedding'] = None  # Placeholder for embedding vectors\n",
    "df_shoes['token_count'] = None  # Placeholder for token counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb25328-66e3-4a39-ac11-e7fded3ff8fd",
   "metadata": {},
   "source": [
    "# Define function for generating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f0ea5b8-4594-436e-8885-ec420eb68695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to generate image and text embeddings\n",
    "def generate_embeddings(df, image_col='image', text_col='product_title', embedding_col='embedding', image_folder=None):\n",
    "\n",
    "    if image_folder is None:\n",
    "        raise ValueError(\"Please provide the path to the image folder.\")\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Generating embeddings\"):\n",
    "        try:\n",
    "\n",
    "            # Read and encode the image as base64\n",
    "            image_path = os.path.join(image_folder, row[image_col])\n",
    "            with open(image_path, 'rb') as img_file:\n",
    "                image_base64 = base64.b64encode(img_file.read()).decode('utf-8')\n",
    "\n",
    "            # Prepare input data for AWS Titan\n",
    "            input_data = {\"inputImage\": image_base64, \"inputText\": row[text_col]}\n",
    "\n",
    "            # Invoke the AWS Titan model via Bedrock runtime\n",
    "            response = bedrock_runtime.invoke_model(\n",
    "                body=json.dumps(input_data),\n",
    "                modelId=\"amazon.titan-embed-image-v1\",\n",
    "                accept=\"application/json\",\n",
    "                contentType=\"application/json\"\n",
    "            )\n",
    "            response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "            # Extract embedding and token count from response\n",
    "            embedding = response_body.get(\"embedding\")\n",
    "            token_count = response_body.get(\"inputTextTokenCount\")\n",
    "\n",
    "            # Validate and save the embedding and token count\n",
    "            if isinstance(embedding, list):\n",
    "                df.at[index, embedding_col] = embedding  # Save embedding as a list\n",
    "                df.at[index, 'token_count'] = int(token_count)  # Save token count as an integer\n",
    "            else:\n",
    "                raise ValueError(\"Unexpected response: embedding is not a list.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error for row {index}: {e}\")\n",
    "            df.at[index, embedding_col] = None  # Handle errors gracefully\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bbec36-60f8-4a87-8d96-851fd8ba3d36",
   "metadata": {},
   "source": [
    "# Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91d0cc26-7334-4487-a130-b7fcc313c48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5bb85b8a4046a1ad898240f0b10a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate embeddings for the product data\n",
    "df_shoes = generate_embeddings(\n",
    "    df=df_shoes, \n",
    "    embedding_col='titan_embedding', \n",
    "    image_folder=IMAGE_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37caa659-5da9-4277-bf36-953d7caf4318",
   "metadata": {},
   "source": [
    "# Save dataset for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a8a38c0-fd8d-4c25-b965-891aeaccd157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with embeddings saved as 'shoes_with_embeddings_token_2025_02_02.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the dataset with generated embeddings to a new CSV file\n",
    "# Get today's date in YYYY_MM_DD format\n",
    "today = datetime.now().strftime('%Y_%m_%d')\n",
    "\n",
    "# Save the dataset with generated embeddings to a CSV file\n",
    "df_shoes.to_csv(f'shoes_with_embeddings_token_{today}.csv', index=False)\n",
    "print(f\"Dataset with embeddings saved as 'shoes_with_embeddings_token_{today}.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346840c1-9e0f-43a3-8819-1848254a6904",
   "metadata": {},
   "source": [
    "# Querying the vectorized data\n",
    "Now that your dataset contains embeddings, we can implement a simple vector similarity search to find the products most relevant to a query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195fb6b9-197d-4eb2-8ed7-01e4a8d32fa1",
   "metadata": {},
   "source": [
    "## Define helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29268d0b-beb4-4951-ac83-814445b73511",
   "metadata": {},
   "source": [
    "### a. Request AWS Titan embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "285825dc-4155-460b-a5f7-cfa02a25a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_embedding(image_base64=None, text_description=None):\n",
    "    \"\"\"\n",
    "    Request embeddings from AWS Titan multimodal model.\n",
    "\n",
    "    Parameters:\n",
    "        image_base64 (str, optional): Base64 encoded image string.\n",
    "        text_description (str, optional): Text description.\n",
    "\n",
    "    Returns:\n",
    "        list: Embedding vector.\n",
    "    \"\"\"\n",
    "    input_data = {\"inputImage\": image_base64, \"inputText\": text_description}\n",
    "    body = json.dumps(input_data)\n",
    "\n",
    "    # Invoke the Titan multimodal model\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=body,\n",
    "        modelId=\"amazon.titan-embed-image-v1\",\n",
    "        accept=\"application/json\",\n",
    "        contentType=\"application/json\"\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "    if response_body.get(\"message\"):\n",
    "        raise ValueError(f\"Embeddings generation error: {response_body.get('message')}\")\n",
    "\n",
    "    return response_body.get(\"embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0767b33e-57a0-4154-b798-5ebc7649e2d0",
   "metadata": {},
   "source": [
    "### b. Cosine similarity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b05d2913-e9d8-4d22-bdce-3140d2093f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarities(query_vec, embeddings):\n",
    "    \"\"\"\n",
    "    Compute cosine similarities between a query vector and a list of embeddings.\n",
    "    \n",
    "    Parameters:\n",
    "        query_vec (list or np.array): Query embedding vector.\n",
    "        embeddings (list of lists): List of product embedding vectors.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Array of cosine similarity scores.\n",
    "    \"\"\"\n",
    "    # Convert lists to NumPy arrays\n",
    "    query_vec = np.array(query_vec).reshape(1, -1)\n",
    "    embeddings = np.array(embeddings)\n",
    "    return cosine_similarity(query_vec, embeddings).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4abc23a-8687-405a-a5d0-29acb8615b0f",
   "metadata": {},
   "source": [
    "### c. Dot product similarity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09792663-e232-42f6-9245-cb66b9de3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dot_product_similarity(query_vec, embeddings):\n",
    "    \"\"\"\n",
    "    Compute dot product similarities between a query vector and a list of embeddings.\n",
    "    \n",
    "    Parameters:\n",
    "        query_vec (list or np.array): The query embedding vector.\n",
    "        embeddings (list of lists): List of product embedding vectors.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Array of dot product similarity scores.\n",
    "    \"\"\"\n",
    "    query_vec = np.array(query_vec).flatten()  # Ensure query is a 1D array\n",
    "    embeddings = np.array(embeddings)\n",
    "    # Compute dot product similarity for each embedding\n",
    "    return np.dot(embeddings, query_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8e6b29-b211-4f52-86aa-3728f725fdcf",
   "metadata": {},
   "source": [
    "## Query your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31129d90-3d3b-4af3-b934-60954e27f202",
   "metadata": {},
   "source": [
    "### a. Prepare the product embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b30ceb32-0526-4c60-bd5e-c8c130506f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_embeddings = df_shoes['titan_embedding'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303cf141-2dd7-41a3-927d-2f0d749fe3a8",
   "metadata": {},
   "source": [
    "### b. Generate a query embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a517cd2-e04a-4292-a4b0-6a195fdb7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_query = \"red heels\"\n",
    "query_embedding = request_embedding(text_description=customer_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b000ed-dac7-48e0-a3d6-26330c4f4bbd",
   "metadata": {},
   "source": [
    "### c. Compute similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b02e4e04-717b-4fa4-b1f2-5a3d47b133db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = compute_cosine_similarities(query_embedding, product_embeddings)\n",
    "dot_similarities = compute_dot_product_similarity(query_embedding, product_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2133d591-daf7-40a5-bcb8-74677424315a",
   "metadata": {},
   "source": [
    "### d. Retrieve top matching products\n",
    "Select the top N similar products based on each similarity measure. \n",
    "\n",
    "Here, `num_neighbors` is set to 6, but you can adjust this number as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03e39772-7366-4d3d-aa8b-5759d2f2bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neighbors = 6  # Change this to the desired number of neighbors\n",
    "top_indices_cosine = np.argsort(cosine_similarities)[::-1][:num_neighbors]\n",
    "top_indices_dot = np.argsort(dot_similarities)[::-1][:num_neighbors]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c008bdbf-3c61-4c39-afca-04e6280142be",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43a1dc8d-ecea-4007-bb97-79283f77deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_neighbors(df, neighbor_indices, image_data_path='data/footwear', width=100):\n",
    "    \"\"\"\n",
    "    Visualize the neighbor products from the cosine similarity search.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing product data.\n",
    "        neighbor_indices (list): List of indices for the neighbor products.\n",
    "        image_data_path (str): Folder path where product images are stored.\n",
    "        width (int): Display width of each image in pixels.\n",
    "    \"\"\"\n",
    "    images_html = \"\"\n",
    "    for idx in neighbor_indices:\n",
    "        product = df.iloc[idx]\n",
    "        img_file = product['image']\n",
    "        product_title = product['product_title']\n",
    "        img_path = os.path.join(image_data_path, img_file)\n",
    "        images_html += (\n",
    "            f'<div style=\"margin-right:10px; text-align:center;\">'\n",
    "            f'<img src=\"{img_path}\" style=\"width:{width}px;\"><br>'\n",
    "            f'<span>{product_title}</span>'\n",
    "            f'</div>'\n",
    "        )\n",
    "    display(HTML(f'<div style=\"display: flex; align-items: center;\">{images_html}</div>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14422cf5-a2d1-486f-bd03-367096fbc458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center;\"><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/748.jpg\" style=\"width:100px;\"><br><span>Hm women red heels</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/778.jpg\" style=\"width:100px;\"><br><span>Hm women red heels</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/908.jpg\" style=\"width:100px;\"><br><span>Portia women red heels</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/985.jpg\" style=\"width:100px;\"><br><span>Portia women red heels</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/10.jpg\" style=\"width:100px;\"><br><span>Id men red shoes</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/1180.jpg\" style=\"width:100px;\"><br><span>Hm women red flats</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center;\"><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/748.jpg\" style=\"width:100px;\"><br><span>Hm women red heels</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/778.jpg\" style=\"width:100px;\"><br><span>Hm women red heels</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/908.jpg\" style=\"width:100px;\"><br><span>Portia women red heels</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/985.jpg\" style=\"width:100px;\"><br><span>Portia women red heels</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/10.jpg\" style=\"width:100px;\"><br><span>Id men red shoes</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/1180.jpg\" style=\"width:100px;\"><br><span>Hm women red flats</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage: Visualize top 5 neighbors (using the indices from the cosine similarity search)\n",
    "visualize_neighbors(df_shoes, top_indices_cosine, image_data_path='../data/footwear', width=100)\n",
    "\n",
    "# Example usage: Visualize top 5 neighbors (using the indices from the cosine similarity search)\n",
    "visualize_neighbors(df_shoes, top_indices_dot, image_data_path='../data/footwear', width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5d71c2-4407-4a30-89c6-b0ae463495eb",
   "metadata": {},
   "source": [
    "## Notes\n",
    "In this example, both cosine and dot product methods returned the same products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c332c3-1148-4cb2-8849-b5659346d160",
   "metadata": {},
   "source": [
    "# Try another query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5ee3bbc-b443-43b9-83d6-4b9b35bc119c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center;\"><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/233.jpg\" style=\"width:100px;\"><br><span>Id men blue shoes</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/251.jpg\" style=\"width:100px;\"><br><span>Id men blue shoes</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/330.jpg\" style=\"width:100px;\"><br><span>Id men blue shoes</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/273.jpg\" style=\"width:100px;\"><br><span>Vans men blue shoes</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/695.jpg\" style=\"width:100px;\"><br><span>Nike women ten blue white shoe</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/1097.jpg\" style=\"width:100px;\"><br><span>Hm women blue flats</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center;\"><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/251.jpg\" style=\"width:100px;\"><br><span>Id men blue shoes</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/330.jpg\" style=\"width:100px;\"><br><span>Id men blue shoes</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/233.jpg\" style=\"width:100px;\"><br><span>Id men blue shoes</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/273.jpg\" style=\"width:100px;\"><br><span>Vans men blue shoes</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/695.jpg\" style=\"width:100px;\"><br><span>Nike women ten blue white shoe</span></div><div style=\"margin-right:10px; text-align:center;\"><img src=\"../data/footwear/1061.jpg\" style=\"width:100px;\"><br><span>Hm women blue flats</span></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "customer_query = \"blue shoes\"\n",
    "query_embedding = request_embedding(text_description=customer_query)\n",
    "cosine_similarities = compute_cosine_similarities(query_embedding, product_embeddings)\n",
    "dot_similarities = compute_dot_product_similarity(query_embedding, product_embeddings)\n",
    "num_neighbors = 6  # Change this to the desired number of neighbors\n",
    "top_indices_cosine = np.argsort(cosine_similarities)[::-1][:num_neighbors]\n",
    "top_indices_dot = np.argsort(dot_similarities)[::-1][:num_neighbors]\n",
    "\n",
    "# Visualize top 5 neighbors (using the indices from the cosine similarity search)\n",
    "visualize_neighbors(df_shoes, top_indices_cosine, image_data_path='../data/footwear', width=100)\n",
    "\n",
    "# Visualize top 5 neighbors (using the indices from the dot product similarity search)\n",
    "visualize_neighbors(df_shoes, top_indices_dot, image_data_path='../data/footwear', width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb35a8b2-da0c-48b8-a242-ca1668528056",
   "metadata": {},
   "source": [
    "## Note\n",
    "You might notice a slight difference in the ranking for **\"blue shoes\"**, illustrating how the two similarity metrics can sometimes produce different results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4242e3e-caca-4c00-9ea8-dbb307ae9310",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've built a vector search solution with AWS Titan, here are some ideas to take your project even further:\n",
    "\n",
    "- **Integrate and experiment:**  \n",
    "  Embed your vector search into your e-commerce platform and try out different similarity metrics (cosine vs. dot product) to fine-tune your recommendations\n",
    "\n",
    "- **Scale your solution:**  \n",
    "  As your product database grows, consider exploring specialized vector search libraries like FAISS or Pinecone for improved performance\n",
    "\n",
    "- **Learn More and Level Up:**  \n",
    "  Ready to build an AI agent that handles complex, multi-color product queries? Check out our free mini-course **\"How to Build an AI Agent to Handle Multi-Color Product Queries\"**:\n",
    "\n",
    "  ![The AI agent looks through the retrieved vector database results and provide a response with recommended shoes](https://d1fiydes8a4qgo.cloudfront.net/blog/2025/january/1/2_agent_response.png \"The AI agent looks through the retrieved vector database results and provide a response with recommended shoes\")\n",
    "\n",
    "\n",
    "In this step-by-step mini-course, you'll learn how to create an AI agent in **Jupyter Notebook** using **Python**, **Pinecone**, and **LlamaIndex** - no deployment required. \n",
    "You'll get hands-on experience building a smarter query engine that goes beyond basic retrieval.\n",
    "\n",
    "<div style=\"text-align: left;\">\n",
    "    <a href=\"https://norahsakal.gumroad.com/l/mini-course-1\" target=\"_blank\" style=\"\n",
    "        background-color: #1976d2;\n",
    "        color: white;\n",
    "        padding: 10px 20px;\n",
    "        border-radius: 5px;\n",
    "        text-decoration: none;\n",
    "        font-family: 'Arial', sans-serif;\n",
    "        font-size: 16px;\n",
    "        font-weight: bold;\n",
    "        display: inline-block;\n",
    "        transition: 0.3s ease-in-out;\n",
    "    \" onmouseover=\"this.style.backgroundColor='#1565c0'\" \n",
    "       onmouseout=\"this.style.backgroundColor='#1976d2'\">\n",
    "        Join for free via Gumroad ↗\n",
    "    </a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a1560-d4e1-44b1-ae03-2ab5cf4903fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
