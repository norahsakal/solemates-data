{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4590f88f",
   "metadata": {},
   "source": [
    "![Cover image](https://d1fiydes8a4qgo.cloudfront.net/blog/2025/january/1/linkedin_card.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d603e936-7f3e-4ea6-a596-9ff123f536cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import base64\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "from typing import Any, List, Optional\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from IPython.display import display, Image, HTML\n",
    "\n",
    "# LlamaIndex\n",
    "from llama_index.core import Document\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.schema import QueryBundle\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "# LlamaIndex agents\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker, AgentRunner\n",
    "\n",
    "# LlamaIndex LLMs\n",
    "from llama_index.llms.openai import OpenAI as OpenAI_Llama\n",
    "\n",
    "# LlamaIndex metadata filters\n",
    "from llama_index.core.vector_stores.types import (\n",
    "    MetadataFilters,FilterCondition\n",
    ")\n",
    "\n",
    "# LlamaIndex retrievers\n",
    "from llama_index.core.retrievers import VectorIndexAutoRetriever, VectorIndexRetriever\n",
    "\n",
    "# LlamaIndex vector stores\n",
    "from llama_index.core.vector_stores import MetadataInfo, VectorStoreInfo\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.core.vector_stores.types import VectorStoreQuery\n",
    "\n",
    "# Pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "import pandas as pd\n",
    "from rapidfuzz import fuzz, process\n",
    "from tqdm import tqdm\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adf505b-3fbd-45b5-9287-913a269763c5",
   "metadata": {},
   "source": [
    "# Load shoe data\n",
    "Let's start by reading the SoleMates shoe dataset. This dataset contains detailed product information, such as shoe colors and heel heights, which we'll transform into embeddings and store in a cloud-based Pinecone vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "850657f5-201c-4bee-803d-e0480a5647da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>product_type</th>\n",
       "      <th>color</th>\n",
       "      <th>usage</th>\n",
       "      <th>color_details</th>\n",
       "      <th>heel_height</th>\n",
       "      <th>heel_type</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_id</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Puma men future cat remix sf black casual shoes</td>\n",
       "      <td>men</td>\n",
       "      <td>casual shoes</td>\n",
       "      <td>black</td>\n",
       "      <td>casual</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>puma</td>\n",
       "      <td>1</td>\n",
       "      <td>1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buckaroo men flores black formal shoes</td>\n",
       "      <td>men</td>\n",
       "      <td>formal shoes</td>\n",
       "      <td>black</td>\n",
       "      <td>formal</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155</td>\n",
       "      <td>buckaroo</td>\n",
       "      <td>2</td>\n",
       "      <td>2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gas men europa white shoes</td>\n",
       "      <td>men</td>\n",
       "      <td>casual shoes</td>\n",
       "      <td>white</td>\n",
       "      <td>casual</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "      <td>gas</td>\n",
       "      <td>3</td>\n",
       "      <td>3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike men's incinerate msl white blue shoe</td>\n",
       "      <td>men</td>\n",
       "      <td>sports shoes</td>\n",
       "      <td>white</td>\n",
       "      <td>sports</td>\n",
       "      <td>[blue]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125</td>\n",
       "      <td>nike</td>\n",
       "      <td>4</td>\n",
       "      <td>4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clarks men hang work leather black formal shoes</td>\n",
       "      <td>men</td>\n",
       "      <td>formal shoes</td>\n",
       "      <td>black</td>\n",
       "      <td>formal</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>clarks</td>\n",
       "      <td>5</td>\n",
       "      <td>5.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     product_title gender  product_type  \\\n",
       "0  Puma men future cat remix sf black casual shoes    men  casual shoes   \n",
       "1           Buckaroo men flores black formal shoes    men  formal shoes   \n",
       "2                       Gas men europa white shoes    men  casual shoes   \n",
       "3        Nike men's incinerate msl white blue shoe    men  sports shoes   \n",
       "4  Clarks men hang work leather black formal shoes    men  formal shoes   \n",
       "\n",
       "   color   usage color_details  heel_height heel_type  price_usd     brand  \\\n",
       "0  black  casual            []          NaN       NaN        220      puma   \n",
       "1  black  formal            []          NaN       NaN        155  buckaroo   \n",
       "2  white  casual            []          NaN       NaN        105       gas   \n",
       "3  white  sports        [blue]          NaN       NaN        125      nike   \n",
       "4  black  formal            []          NaN       NaN        220    clarks   \n",
       "\n",
       "   product_id  image  \n",
       "0           1  1.jpg  \n",
       "1           2  2.jpg  \n",
       "2           3  3.jpg  \n",
       "3           4  4.jpg  \n",
       "4           5  5.jpg  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the SoleMates shoe dataset\n",
    "df_shoes = pd.read_csv('../data/solemates_shoe_directory.csv')\n",
    "\n",
    "# Convert 'color_details' from string representation of a list to an actual list\n",
    "df_shoes['color_details'] = df_shoes['color_details'].apply(ast.literal_eval)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df_shoes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f734f7e2-e2e6-4b5d-8c1d-f70ec2db31ea",
   "metadata": {},
   "source": [
    "# Visualize shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01949bfe-ac5f-483f-af35-b12858b5c598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center;\"><img src=\"data/footwear/1.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/2.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/3.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/4.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/5.jpg\" style=\"width:100px; margin-right:10px;\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "width = 100\n",
    "images_html = \"\"\n",
    "image_data_path = '../data/footwear'\n",
    "for img_file in df_shoes.head()['image']:\n",
    "    img_path = os.path.join(image_data_path, img_file)\n",
    "    # Add each image as an HTML <img> tag\n",
    "    images_html += f'<img src=\"{img_path}\" style=\"width:{width}px; margin-right:10px;\">'\n",
    "# Display all images in a row using HTML\n",
    "display(HTML(f'<div style=\"display: flex; align-items: center;\">{images_html}</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a68f98-2d7d-4c03-94d6-87583b4ce9b0",
   "metadata": {},
   "source": [
    "# Cost of vectorization and pre-embedded dataset\n",
    "Vectorizing datasets with AWS Bedrock and the Titan multimodal model involves costs based on the number of input tokens and images:\n",
    "\n",
    "- **Text embeddings:** $0.0008 per 1,000 input tokens\n",
    "\n",
    "- **Image embeddings:** $0.00006 per image\n",
    "\n",
    "The provided SoleMates dataset is small, containing just **1306 pairs of shoes**, making it affordable to vectorize. For this dataset, I calculated the total cost of vectorization and summarized the token counts below:\n",
    "\n",
    "- **Token Count:** 12746 tokens\n",
    "- **Images:** 1306\n",
    "- **Total Cost:** $0.0885568\n",
    "\n",
    "If you prefer not to generate embeddings yourself or don't have access to AWS, you can use a pre-embedded dataset that I've prepared as a CSV file. This file includes all embeddings and token counts, allowing you to follow the guide without incurring additional costs. However, for hands-on experience, I recommend running the embedding process to understand the workflow.\n",
    "\n",
    "To load the pre-embedded dataset, use the following code:\n",
    "\n",
    "```python\n",
    "# Load pre-embedded dataset\n",
    "df_shoes_with_embeddings = pd.read_csv('../data/solemates_shoe_directory_with_embeddings_token_count.csv')\n",
    "\n",
    "# Convert string representations to actual lists\n",
    "df_shoes_with_embeddings['titan_embedding'] = df_shoes_with_embeddings['titan_embedding'].apply(ast.literal_eval)\n",
    "```\n",
    "\n",
    "**This step is entirely optional and designed to accommodate various levels of access and resources.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c638367-c8c7-4177-acef-d4a11b7d8e1b",
   "metadata": {},
   "source": [
    "# Set up AWS Bedrock client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804e8787-5125-4d1d-b535-1b670798e559",
   "metadata": {},
   "source": [
    "You'll need access to Amazon Bedrock foundation models.\n",
    "\n",
    "### What is AWS Bedrock?\n",
    "Amazon Bedrock is a fully managed service offering high-performing foundation models (FMs) for building generative AI applications.\n",
    "\n",
    "Bedrock is serverless and offers multiple foundational models to choose between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6bdd7eb-654e-430b-a848-8d28795376db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your AWS profile\n",
    "# Replace AWS_PROFILE with the name of your AWS CLI profile\n",
    "# To use your default AWS profile, leave 'aws_profile' as None\n",
    "aws_profile = os.environ.get('AWS_PROFILE')\n",
    "\n",
    "# Specify the AWS region where Bedrock is available\n",
    "aws_region_name = \"us-east-1\"\n",
    "\n",
    "try:\n",
    "    # Set the default session for the specified profile\n",
    "    if aws_profile:\n",
    "        boto3.setup_default_session(profile_name=aws_profile)\n",
    "    else:\n",
    "        boto3.setup_default_session()  # Use default AWS profile if none is specified\n",
    "\n",
    "    # Initialize the Bedrock runtime client\n",
    "    bedrock_runtime = boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=aws_region_name\n",
    "    )\n",
    "except NoCredentialsError:\n",
    "    print(\"AWS credentials not found. Please configure your AWS profile.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1a4e4b-38bf-47ff-9005-ae64361f1105",
   "metadata": {},
   "source": [
    "# Generate embeddings for product data\n",
    "To prepare our product data for the vector database, we'll generate embeddings for each product using AWS Titan. These embeddings combine image and text data to represent each product in a format suitable for search and recommendation systems.\n",
    "\n",
    "Before generating embeddings, we'll initialize two new columns in the dataset:\n",
    "\n",
    "- **titan_embedding:** To store the embedding vectors\n",
    "- **token_count:** To store the token count for each product title\n",
    "\n",
    "Then, we'll define a function to generate embeddings and apply it to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4db6a7d-7e11-45b3-a69b-0882a1e8f1cd",
   "metadata": {},
   "source": [
    "# Initialize columns for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "526f27e6-ce77-474e-96f8-7eff1ae2c8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize columns to store embeddings and token counts\n",
    "df_shoes['titan_embedding'] = None  # Placeholder for embedding vectors\n",
    "df_shoes['token_count'] = None  # Placeholder for token counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56eb5ec-7938-489f-b877-4316d6ab9a72",
   "metadata": {},
   "source": [
    "# Define function for generating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30baed6c-968e-4b0e-82f4-b56b6c804d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to generate image and text embeddings\n",
    "def generate_embeddings(df, image_col='image', text_col='product_title', embedding_col='embedding', image_folder=None):\n",
    "\n",
    "    if image_folder is None:\n",
    "        raise ValueError(\"You must specify an image folder path.\")\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Generating embeddings\"):\n",
    "        try:\n",
    "            # Prepare image file as base64\n",
    "            image_path = os.path.join(image_folder, row[image_col])\n",
    "            with open(image_path, 'rb') as img_file:\n",
    "                image_base64 = base64.b64encode(img_file.read()).decode('utf-8')\n",
    "\n",
    "            # Create input data for the model\n",
    "            input_data = {\"inputImage\": image_base64, \"inputText\": row[text_col]}\n",
    "\n",
    "            # Invoke AWS Titan model via Bedrock runtime\n",
    "            response = bedrock_runtime.invoke_model(\n",
    "                body=json.dumps(input_data),\n",
    "                modelId=\"amazon.titan-embed-image-v1\",\n",
    "                accept=\"application/json\",\n",
    "                contentType=\"application/json\"\n",
    "            )\n",
    "            response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "            # Extract embedding and token count from response\n",
    "            embedding = response_body.get(\"embedding\")\n",
    "            token_count = response_body.get(\"inputTextTokenCount\")\n",
    "\n",
    "            # Validate and save the embedding\n",
    "            if isinstance(embedding, list):\n",
    "                df.at[index, embedding_col] = embedding  # Save embedding as a list\n",
    "                df.at[index, 'token_count'] = int(token_count)  # Save token count as an integer\n",
    "            else:\n",
    "                raise ValueError(\"Embedding is not a list as expected.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error for row {index}: {e}\")\n",
    "            df.at[index, embedding_col] = None  # Handle errors gracefully\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe8d3e6-8499-461a-8f01-b42101a6c0f8",
   "metadata": {},
   "source": [
    "# Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3a62d1c-9a36-4262-b9bf-95fd76206839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351f5b351064416bb37923c281ce6456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate embeddings for the product data\n",
    "df_shoes = generate_embeddings(\n",
    "    df=df_shoes, \n",
    "    embedding_col='titan_embedding', \n",
    "    image_folder='../data/footwear'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16805ab1-a449-425a-b0a4-940d9f8b021d",
   "metadata": {},
   "source": [
    "# Save dataset for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b31087b9-c477-4075-8a2f-63b9a84cb241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with embeddings saved as 'shoes_with_embeddings_token_2025_01_29.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the dataset with generated embeddings to a new CSV file\n",
    "# Get today's date in YYYY_MM_DD format\n",
    "today = datetime.now().strftime('%Y_%m_%d')\n",
    "\n",
    "# Save the dataset with generated embeddings to a CSV file\n",
    "df_shoes.to_csv(f'shoes_with_embeddings_token_{today}.csv', index=False)\n",
    "print(f\"Dataset with embeddings saved as 'shoes_with_embeddings_token_{today}.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd90cc1-a6e4-4c2f-af4c-02a9702b71a6",
   "metadata": {},
   "source": [
    "# Create a dictionary with product data\n",
    "\n",
    "Before we create LlamaIndex Document objects, we need to structure the product data into dictionaries. These dictionaries include:\n",
    "\n",
    "1. **Text:** The product title that will be used for embedding queries\n",
    "2. **Metadata:** A dictionary containing detailed attributes for each product (e.g., color, gender, usage, price)\n",
    "3. **Embedding:** The Titan embeddings generated earlier\n",
    "\n",
    "This dictionary format ensures the data is well-organized for creating Document objects in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dee3ce5-e408-46dc-9df1-b5886449c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame rows into a list of dictionaries for LlamaIndex\n",
    "product_data = df_shoes.apply(lambda row: {\n",
    "    'text': row['product_title'],\n",
    "    'metadata': {\n",
    "        'color': row['color'],\n",
    "        'text': row['product_title'],\n",
    "        'gender': row['gender'],\n",
    "        'product_type': row['product_type'],\n",
    "        'usage': row['usage'],\n",
    "        'price': row['price_usd'],\n",
    "        'product_id': row['product_id'],\n",
    "        'brand': row['brand'],\n",
    "        **({'heel_height': float(row['heel_height'])} if not pd.isna(row['heel_height']) else {}),\n",
    "        **({'heel_type': row['heel_type']} if not pd.isna(row['heel_type']) else {}),\n",
    "        **({'color_details': row['color_details']} if row['color_details'] else {})\n",
    "    },\n",
    "    'embedding': row['titan_embedding']\n",
    "}, axis=1).tolist()\n",
    "\n",
    "# Preview the first product dictionary\n",
    "#product_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e3913b-261a-484f-8f55-31ff3ec25cce",
   "metadata": {},
   "source": [
    "# Create LlamaIndex Documents\n",
    "We'll now use the product data dictionaries to create LlamaIndex `Document` objects.\n",
    "\n",
    "These `Documents` are crucial because:\n",
    "\n",
    "- They act as containers for our product data and embeddings.\n",
    "- They enable seamless interaction with Pinecone for upserting embeddings.\n",
    "\n",
    "Each `Document` includes:\n",
    "\n",
    "1. The **text** (product_title) for embedding and query purposes\n",
    "2. **Metadata** with attributes like color, gender, and price\n",
    "3. The AWS Titan multimodal **embedding** generated earlier\n",
    "4. An **exclusion list** (excluded_embed_metadata_keys) to prevent unnecessary metadata fields from being embedded, ensuring optimal performance and cost-efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c38e73-0084-441b-a184-bfc2ea708e44",
   "metadata": {},
   "source": [
    "# Create LlamaIndex Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "661df2b7-1783-4040-8fd9-6eb1650305b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'color': 'black',\n",
       " 'text': 'Puma men future cat remix sf black casual shoes',\n",
       " 'gender': 'men',\n",
       " 'product_type': 'casual shoes',\n",
       " 'usage': 'casual',\n",
       " 'price': 220,\n",
       " 'product_id': 1,\n",
       " 'brand': 'puma'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create LlamaIndex Document objects\n",
    "documents = []\n",
    "for doc in product_data:\n",
    "    documents.append(\n",
    "        Document(\n",
    "            text=doc[\"text\"],\n",
    "            extra_info=doc[\"metadata\"],\n",
    "            embedding=doc['embedding'],\n",
    "\n",
    "            # Avoid embedding unnecessary metadata\n",
    "            excluded_embed_metadata_keys=[\n",
    "                'color',\n",
    "                'gender',\n",
    "                'product_type',\n",
    "                'usage',\n",
    "                'text',\n",
    "                'price',\n",
    "                'product_id',\n",
    "                'brand',\n",
    "                'heel_height',\n",
    "                'heel_type',\n",
    "                'color_details'\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Confirm the first Document object\n",
    "documents[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83953b49-39f2-427b-8584-58c247c3f0a4",
   "metadata": {},
   "source": [
    "# Add local environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf2949d6-93c6-404a-b729-e2ff7e5ce966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Pinecone API Key is: pcsk_4rG*******************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to the .env file\n",
    "dotenv_path = './.env' \n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv(dotenv_path=dotenv_path, override=True)\n",
    "\n",
    "# Access the OPENAI_API_KEY\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "\n",
    "# Print the key (optional, for testing purposes)\n",
    "print(f\"Your Pinecone API Key is: {pinecone_api_key[:8]}{'*' * (len(pinecone_api_key) - 8)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5219ad-7144-4e70-86b9-d98d9b17ee16",
   "metadata": {},
   "source": [
    "# Initialize Pinecone\n",
    "To interact with Pinecone, you'll first need an account and API keys. If you don't already have them, [create a Pinecone account ↗](https://www.pinecone.io/) and retrieve your API key.\n",
    "\n",
    "Pinecone is a vector database designed to store and query embeddings. We'll use Pinecone to upsert the AWS Titan embeddings we generated earlier, enabling efficient similarity and hybrid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ea82fa1-6f50-467e-9cad-80e2199c62e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone client with API key\n",
    "pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))\n",
    "index_name = \"solemates\"  # Replace with your desired index name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310c942e-09d5-43a6-a433-e77a36863f47",
   "metadata": {},
   "source": [
    "# List current indexes\n",
    "Let's list the existing indexes in your Pinecone account to ensure no duplicates before creating a new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd7c4b30-10b0-47f8-ae5d-7292d1176c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexes': []}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List current indexes\n",
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83803d6-7017-4f04-945a-8f75b3889196",
   "metadata": {},
   "source": [
    "# Create Index\n",
    "Next, we'll create a Pinecone index. An index stores the embeddings and metadata for your data.\n",
    "\n",
    "- **Dimension:** Matches the size of the embeddings we're using (1024 for AWS Titan multimodal embeddings)\n",
    "- **Metric:** Defines how similarity is calculated (e.g., dot product, cosine similarity)\n",
    "- **ServerlessSpec:** Specifies the cloud provider and region for your index\n",
    "\n",
    "If the index already exists, this step will be skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b848ce58-96a3-4f80-99eb-b96f63e4e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name, # The index name you picked earlier\n",
    "        dimension=1024,  # AWS Titan embeddings require 1024 dimensions\n",
    "        metric=\"dotproduct\",  # Required for hybrid search with Pinecone\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c1dfd2-07a6-46e7-8a1c-09a8b7bfcb1b",
   "metadata": {},
   "source": [
    "## Inspect Pinecone\n",
    "Navigate to your Pinecone dashboard, and you should see your new index with 0 records (vectors), as we haven't populated it with our vectors yet:\n",
    "\n",
    "![Check your Pinecone index](https://norahsakal.com/assets/images/1_vector_db_empty-0ace534dc05ce707ac99c961c06c4d50.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaa996d-c079-4a7d-988f-abae034760f6",
   "metadata": {},
   "source": [
    "# Initialize Pinecone Index\n",
    "After creating the index, we'll initialize it for further operations like upserting embeddings and querying vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa05a36e-ef61-4f5e-a6a0-fa6c544ccfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08961fc1-588b-431f-b1f4-2b31a51f4065",
   "metadata": {},
   "source": [
    "# Create Pinecone Vector Store\n",
    "We'll now set up a **Pinecone Vector Store** using LlamaIndex.\n",
    "\n",
    "This vector store connects our Pinecone index with the LlamaIndex framework.\n",
    "\n",
    "Key configuration details:\n",
    "\n",
    "1. **Namespace:** A logical grouping within the index, allowing future addition of other product types\n",
    "2. **Hybrid Search:** Enabling both semantic and keyword search by adding sparse vectors\n",
    "\n",
    "For more information:\n",
    "\n",
    "- [Pinecone Namespaces Guide ↗](https://docs.pinecone.io/guides/indexes/use-namespaces)\n",
    "- [Hybrid Search Introduction ↗](https://www.pinecone.io/learn/hybrid-search-intro/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "731c1262-c3cd-46c7-b83b-a7ed71460156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "vector_store = PineconeVectorStore(\n",
    "    pinecone_index=pinecone_index,\n",
    "    namespace='footwear',  # Logical namespace for shoe data\n",
    "    add_sparse_vector=True  # Enables hybrid search\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db33052e-3a1f-4685-90a6-d86d0509104a",
   "metadata": {},
   "source": [
    "# Create an ingestion pipeline\n",
    "We'll create an **Ingestion Pipeline** to upsert our vectors into the Pinecone index. No transformations are required since we've pre-generated embeddings with AWS Titan.\n",
    "\n",
    ">**Note:** As of January 29 2025, LlamaIndex doesn't abstract AWS Titan multimodal embeddings, so we're using our own vectors directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30c32ab2-5901-4b7e-bf21-660723a95bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = IngestionPipeline(\n",
    "    transformations=[],  # No transformations since we pre-generated our embeddings\n",
    "    vector_store=vector_store\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9b91b0-7cf5-4fdc-921f-29fb3c917caa",
   "metadata": {},
   "source": [
    "# Run the ingestion pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bedb276-dec0-4ccd-8515-f88e54dee588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the pipeline to upsert embeddings into Pinecone\n",
    "pipeline.run(documents=documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b64fde-c55a-4586-920d-1e8675a7c2d5",
   "metadata": {},
   "source": [
    "# Inspect your Pinecone index\n",
    "\n",
    "Now that we've upserted the vectors, navigate back to Pinecone. You should see **1306** records in your index, corresponding to the embeddings we added:\n",
    "\n",
    "![Navigate back to your Pinecone, you should see 1306 records](https://norahsakal.com/assets/images/2_vector_db_with_records-af929a625f221f9e8db01080703422f3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91065677-0ba7-4865-84f7-ee3af4d0313e",
   "metadata": {},
   "source": [
    "# Query the Vector Database Directly (Without Query Engine or Chat Engine)\n",
    "Before we use a **Query Engine** or **Chat Engine** to interact with the vector database, we'll start with a direct query using a simple retriever.\n",
    "\n",
    "This approach demonstrates how you can fetch relevant records from the database without involving advanced reasoning, natural language understanding, or conversation tracking. It's a fundamental way to confirm that the embeddings and metadata are stored correctly and the vector database is functioning as expected.\n",
    "\n",
    "Next, we'll move on to more advanced querying techniques, including using a **Query Engine** and an **AI Agent** to leverage the power of LLMs.\n",
    "\n",
    "The first step is creating a simple retriever, but first, we need to define a custom embedding function.\n",
    "\n",
    "As of **January 29, 2024, LlamaIndex does not abstract AWS Titan multimodal embeddings**, so we'll implement a custom class for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611fda2a-da1b-4197-86d4-dd568fc54e88",
   "metadata": {},
   "source": [
    "# Define helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db95468b-8881-4a78-ac06-ca62ef6d5ef5",
   "metadata": {},
   "source": [
    "## Define function to request AWS Titan embeddings\n",
    "We'll define a helper function to request embeddings from AWS Titan's multimodal model. This function will handle both text and image inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e45df7eb-8282-4931-a2e2-0266b3d364dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_embedding(image_base64=None, text_description=None):\n",
    "    \"\"\"\n",
    "    Request embeddings from AWS Titan multimodal model.\n",
    "\n",
    "    Parameters:\n",
    "        image_base64 (str, optional): Base64 encoded image string.\n",
    "        text_description (str, optional): Text description.\n",
    "\n",
    "    Returns:\n",
    "        list: Embedding vector.\n",
    "    \"\"\"\n",
    "    input_data = {\"inputImage\": image_base64, \"inputText\": text_description}\n",
    "    body = json.dumps(input_data)\n",
    "\n",
    "    # Invoke the Titan multimodal model\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=body,\n",
    "        modelId=\"amazon.titan-embed-image-v1\",\n",
    "        accept=\"application/json\",\n",
    "        contentType=\"application/json\"\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "    if response_body.get(\"message\"):\n",
    "        raise ValueError(f\"Embeddings generation error: {response_body.get('message')}\")\n",
    "\n",
    "    return response_body.get(\"embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1126d5-25c4-4560-a885-63810add46e2",
   "metadata": {},
   "source": [
    "## Define custom embedding class\n",
    "We'll now define a custom embedding class that uses the AWS Titan multimodal model to fetch embeddings.\n",
    "\n",
    "This class overrides key methods in LlamaIndex's BaseEmbedding to integrate AWS Titan into the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59bde2e9-4d29-42bf-a1a3-4e2f78ff1819",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalEmbeddings(BaseEmbedding):\n",
    "    \"\"\"\n",
    "    Custom embedding class for AWS Titan multimodal embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs: Any) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def class_name(cls) -> str:\n",
    "        return \"multimodal\"\n",
    "\n",
    "    async def _aget_query_embedding(self, query: str) -> List[float]:\n",
    "        return self._get_query_embedding(query)\n",
    "\n",
    "    async def _aget_text_embedding(self, text: str) -> List[float]:\n",
    "        return self._get_text_embedding(text)\n",
    "\n",
    "    def _get_query_embedding(self, query: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        Get embeddings for a query string.\n",
    "        \"\"\"\n",
    "        return request_embedding(text_description=query)\n",
    "\n",
    "    def _get_text_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        Get embeddings for a text string.\n",
    "        \"\"\"\n",
    "        return request_embedding(text_description=text)\n",
    "\n",
    "    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Get embeddings for a batch of text strings.\n",
    "        \"\"\"\n",
    "        return [request_embedding(text_description=text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3621ba9-3f65-4775-bc8e-c9095e27399f",
   "metadata": {},
   "source": [
    "## Instantiate the Custom Class\n",
    "We'll now instantiate the MultimodalEmbeddings class to use it in our retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09ae7292-7f3c-41cf-8d28-b79dc9a05974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the custom embedding model\n",
    "embed_model = MultimodalEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5a5169-ff62-4ab1-8ff2-e8fbca3c3eb6",
   "metadata": {},
   "source": [
    "## Create a Vector Store Index\n",
    "We'll start by creating a **Vector Store Index** with `LlamaIndex`. This index will allow us to query the Pinecone index using the same vector store we initialized earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5c339ea-98a0-40e2-bb56-d5546b7329d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Vector Store Index\n",
    "vector_index = VectorStoreIndex.from_vector_store(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90870ac-49f9-45ab-aee9-a330acf64edc",
   "metadata": {},
   "source": [
    "## Create a simple retriever\n",
    "We'll create a simple retriever using the custom embedding model and the vector index.\n",
    "\n",
    "Key configurations:\n",
    "\n",
    "1. **similarity_top_k:** Number of top results to retrieve\n",
    "2. **vector_store_query_mode:** Set to **\"hybrid\"** for combining semantic and keyword search\n",
    "3. **alpha:** Weighting between semantic (embedding) and keyword search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57717883-34bf-4f92-8533-e57374791472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=vector_index,\n",
    "    embed_model=embed_model,\n",
    "    similarity_top_k=8,  # Retrieve the top 8 results\n",
    "    vector_store_query_mode=\"hybrid\",  # Enable hybrid search\n",
    "    alpha=0.5  # Weighting between semantic and keyword search\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb74b249-9642-4ce1-889e-ffb800c3d588",
   "metadata": {},
   "source": [
    "# Query Vector Database Directly Using a Simple Retriever\n",
    "We'll use a simple retriever to query the vector database and inspect the results. This method interacts with the embeddings and metadata in a straightforward way, without utilizing an LLM-powered **Query Engine** or **Chat Engine**.\n",
    "\n",
    "**Why this step matters:**\n",
    "\n",
    "1. Validates that the vector database is populated correctly\n",
    "2. Shows how to query embeddings directly, bypassing the overhead of LLM-based reasoning\n",
    "3. Prepares the groundwork for building advanced workflows with Query Engines and Agents\n",
    "\n",
    "In the next steps, we'll extend this retriever to integrate with an LLM-powered Query Engine for richer responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98a7da3b-d9c7-46d3-95b1-03c57d858134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 2.2923\n",
      "Text: Id men red shoes\n",
      "--------------------------------------------------\n",
      "Score: 2.2458\n",
      "Text: Arrow men red shoes\n",
      "--------------------------------------------------\n",
      "Score: 2.2390\n",
      "Text: Catwalk women red shoes\n",
      "--------------------------------------------------\n",
      "Score: 2.2381\n",
      "Text: Vans men red old skool shoes\n",
      "--------------------------------------------------\n",
      "Score: 2.2366\n",
      "Text: Cobblerz women red shoes\n",
      "--------------------------------------------------\n",
      "Score: 2.2335\n",
      "Text: Converse men black & red shoes\n",
      "--------------------------------------------------\n",
      "Score: 2.2253\n",
      "Text: Converse men red casual shoes\n",
      "--------------------------------------------------\n",
      "Score: 2.2251\n",
      "Text: Fila men leonard red shoes\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Query the vector store for \"red shoes\"\n",
    "results = retriever.retrieve(\"red shoes\")\n",
    "\n",
    "# Display results\n",
    "for item in results:\n",
    "    score = item.score\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    print(f\"Text: {item.get_content()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66153e4-bb8b-463b-80a2-62d8432d97fc",
   "metadata": {},
   "source": [
    "## Visualize Vector Database Pull\n",
    "The vector database query returns a list of red shoes based on the embeddings. To verify the results, let's visualize the pulled vectors.\n",
    "\n",
    "We'll create a function that loops through the retrieved nodes and displays each image along with its metadata in a row for easy inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d43c3b0-f0e7-4a71-bfe7-cdd35ffd16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_nodes_with_images_in_row(vector_database_response_nodes, image_folder_path=None, img_width=100):\n",
    "    html_content = \"<div style='display: flex; flex-wrap: wrap; gap: 20px;'>\"\n",
    "\n",
    "    if image_folder_path is None:\n",
    "        raise ValueError(\"You must specify an image folder path.\")\n",
    "\n",
    "    for node in vector_database_response_nodes:\n",
    "        # Retrieve text and product_id from node metadata\n",
    "        text = node.metadata.get('text')\n",
    "        product_id = node.metadata.get('product_id')\n",
    "\n",
    "        # Generate image path based on product_id\n",
    "        image_path = os.path.join(image_folder_path, f\"{product_id}.jpg\")\n",
    "\n",
    "        if os.path.exists(image_path):\n",
    "            # Add each text and image in a flex container\n",
    "            html_content += f\"\"\"\n",
    "                <div style=\"text-align: center;\">\n",
    "                    <p>{text}</p>\n",
    "                    <img src='{image_path}' width='{img_width}px' style=\"padding: 5px;\"/>\n",
    "                </div>\n",
    "            \"\"\"\n",
    "        else:\n",
    "            # Handle missing images gracefully\n",
    "            html_content += f\"\"\"\n",
    "                <div style=\"text-align: center;\">\n",
    "                    <p>{text}</p>\n",
    "                    <p style='color: red;'>Image not found for product_id {product_id}</p>\n",
    "                </div>\n",
    "            \"\"\"\n",
    "\n",
    "    # Close the main div\n",
    "    html_content += \"</div>\"\n",
    "\n",
    "    # Display the content as HTML\n",
    "    display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f42e07-8ede-453c-9731-ed1f1b541036",
   "metadata": {},
   "source": [
    "# Visualize Shoes\n",
    "Let's visualize the shoes retrieved from the vector database to confirm that the results match the query for \"red shoes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f2272eb-c4b4-4fb3-a4d7-a26418eb4a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display: flex; flex-wrap: wrap; gap: 20px;'>\n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Id men red shoes</p>\n",
       "                    <img src='data/footwear/10.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Arrow men red shoes</p>\n",
       "                    <img src='data/footwear/277.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Catwalk women red shoes</p>\n",
       "                    <img src='data/footwear/917.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Vans men red old skool shoes</p>\n",
       "                    <img src='data/footwear/136.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Cobblerz women red shoes</p>\n",
       "                    <img src='data/footwear/1278.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Converse men black & red shoes</p>\n",
       "                    <img src='data/footwear/160.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Converse men red casual shoes</p>\n",
       "                    <img src='data/footwear/171.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Fila men leonard red shoes</p>\n",
       "                    <img src='data/footwear/94.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_nodes_with_images_in_row(results, image_folder_path='../data/footwear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fbe676-3205-453d-961d-852dac99f72b",
   "metadata": {},
   "source": [
    "# Examine the shoes\n",
    "As shown, all the retrieved shoes are red or have red details, confirming that the naive vector index query works well for focused queries like red shoes:\n",
    "\n",
    "![As shown, all the retrieved shoes are red or have red details](https://norahsakal.com/assets/images/3_vector_query_pull-fdb72ce1fbd5b2651ba3dab057816d97.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31687cbf-51f4-4402-b581-b300c1bc5a8a",
   "metadata": {},
   "source": [
    "## Why not keep using the index alone?\n",
    "But the vector database pull of red shoes looks great, so why even involve an LLM?\n",
    "\n",
    "Before we add an LLM, let's try to query the vector database again, but this time with something unrelated, like a **\"Thank you!\"** from the customer and examine the new response:\n",
    "\n",
    "![Let's try to query our vector database with something unrelated, like \"Thank you!\"](https://norahsakal.com/assets/images/4_unrelated_reply-4aff8ef88d4d0cfc39285004aab64960.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f37743f-9932-429c-8f31-c5441848a031",
   "metadata": {},
   "source": [
    "# Test an unrelated query\n",
    "Let's run the previous code snippet again, but this time, use the query **\"Thank you!\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f10b3dfd-1abe-4240-8252-706d5fa3d3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.1846\n",
      "Text: Timberland women femmes brown boot\n",
      "--------------------------------------------------\n",
      "Score: 1.1839\n",
      "Text: Adidas women color can pink shoes\n",
      "--------------------------------------------------\n",
      "Score: 1.1784\n",
      "Text: Nike men's air max black shoe\n",
      "--------------------------------------------------\n",
      "Score: 1.1750\n",
      "Text: Id men red shoes\n",
      "--------------------------------------------------\n",
      "Score: 1.1746\n",
      "Text: Adidas originals women superstar 2 white casual shoes\n",
      "--------------------------------------------------\n",
      "Score: 1.1744\n",
      "Text: Timberland women femmes brown casual shoes\n",
      "--------------------------------------------------\n",
      "Score: 1.1732\n",
      "Text: Nike women's transform iii in black pink shoe\n",
      "--------------------------------------------------\n",
      "Score: 1.1726\n",
      "Text: Vans men khaki shoes\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Query the vector store with an unrelated query\n",
    "results = retriever.retrieve(\"Thank you!\") # Try an unrelated query\n",
    "\n",
    "# Display results\n",
    "for item in results:\n",
    "    score = item.score\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    print(f\"Text: {item.get_content()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62075f1-a460-41bd-8dae-9c4290f928a3",
   "metadata": {},
   "source": [
    "# Visualize pulled shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0f40982-d7b3-4c8b-bc01-77837a170a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display: flex; flex-wrap: wrap; gap: 20px;'>\n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Timberland women femmes brown boot</p>\n",
       "                    <img src='data/footwear/1154.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Adidas women color can pink shoes</p>\n",
       "                    <img src='data/footwear/1209.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Nike men's air max black shoe</p>\n",
       "                    <img src='data/footwear/148.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Id men red shoes</p>\n",
       "                    <img src='data/footwear/10.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Adidas originals women superstar 2 white casual shoes</p>\n",
       "                    <img src='data/footwear/1004.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Timberland women femmes brown casual shoes</p>\n",
       "                    <img src='data/footwear/1143.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Nike women's transform iii in black pink shoe</p>\n",
       "                    <img src='data/footwear/759.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Vans men khaki shoes</p>\n",
       "                    <img src='data/footwear/11.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_nodes_with_images_in_row(results, image_folder_path='../data/footwear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a0b9c9-ac97-4a04-900f-254c45062e65",
   "metadata": {},
   "source": [
    "# Limitations of a naive RAG system\n",
    "As seen, regardless of the query, the vector database matches the closest vectors based on the embeddings.\n",
    "\n",
    "In this case, querying with **\"Thank you!\"** still returns shoes that have vectors most similar to the vectorized **\"Thank you!\"**:\n",
    "\n",
    "![Regardless of the query, the vector database matches the closest vectors based on the embeddings](https://norahsakal.com/assets/images/5_unrelated_pull-71472284ac5d2f808254e648e7eaa7bd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf3d410-716c-400a-8b9d-fce9f06503e6",
   "metadata": {},
   "source": [
    "# Create query engine\n",
    "To overcome the limitations of naive queries, we'll integrate an LLM into our workflow by creating a Query Engine.\n",
    "\n",
    "This Query Engine will:\n",
    "\n",
    "1. Interpret the user's natural language input\n",
    "2. Retrieve contextually relevant information from the vector database\n",
    "3. Enable more dynamic and flexible interactions with the data\n",
    "\n",
    "For this guide, we'll use the `openai-o4` model for the LLM, but LlamaIndex supports various other LLMs.\n",
    "\n",
    "- [Supported LLMs ↗](https://docs.llamaindex.ai/en/stable/module_guides/models/llms/modules/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ac5999-3adb-4b52-8fd8-4aa9f25f1a7f",
   "metadata": {},
   "source": [
    "## OpenAI AP keys\n",
    "For this next step you'll nedd to add your OpenAI API key.\n",
    "\n",
    "Navigate to your [OpenAI dashboard ](https://platform.openai.com/api-keys) and generate a new API key:\n",
    "\n",
    "![Navigate to your OpenAI dashboard and generate API keys](https://d1fiydes8a4qgo.cloudfront.net/blog/2025/1_generate_api_keys.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79076d75-10bd-49a6-8c41-f2f572d32d64",
   "metadata": {},
   "source": [
    "# Read OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bb845351-43e9-4f9f-9807-4006aecc01d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Pinecone API Key is: pcsk_4rG*******************************************************************\n",
      "Your OpenAI API Key is: sk-9wvMO*******************************************\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to the .env file\n",
    "dotenv_path = './.env' \n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv(dotenv_path=dotenv_path, override=True)\n",
    "\n",
    "# Access the OPENAI_API_KEY\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY') # Newly added OpenAI API key\n",
    "\n",
    "# Print the key (optional, for testing purposes)\n",
    "print(f\"Your Pinecone API Key is: {pinecone_api_key[:8]}{'*' * (len(pinecone_api_key) - 8)}\")\n",
    "print(f\"Your OpenAI API Key is: {openai_api_key[:8]}{'*' * (len(openai_api_key) - 8)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962dd067-9007-4d8f-a8b5-e8890fa80fcd",
   "metadata": {},
   "source": [
    "# Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f09e87ff-4b95-4fdf-8b69-d70ab733917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = OpenAI_Llama(\n",
    "    temperature=0.0,\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=os.getenv('OPENAI_API_KEY')\n",
    ")\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d0dec9-af22-4a3f-b33c-53a5e2ca769d",
   "metadata": {},
   "source": [
    "# Create Query Engine\n",
    "We'll now create a Query Engine using the vector index and our custom embedding model. This engine will leverage the LLM for intelligent query interpretation and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b91d84f3-e9c9-488e-91b7-287257fe718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query engine from the vector index\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    embed_model=embed_model,\n",
    "    similarity_top_k=8,\n",
    "    vector_store_query_mode=\"hybrid\",\n",
    "    alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb02e691-02e0-4dc4-865d-8cbaddc88ac3",
   "metadata": {},
   "source": [
    "# Test query engine with today's challenge\n",
    "Remember our challenge, a customer asking about black shoes with red details:\n",
    "\n",
    "**Customer:** \"I need women's black shoes with red details\":\n",
    "\n",
    "![Our challenge is a customer that asks about women's black shoes with red details](https://norahsakal.com/assets/images/1_user_inquiry-f2a38240854cbb44f5a6c2412c48d7a8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8a7e315-1342-4e44-b1a2-037dd6f5cad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot response:  The Nike women's transform iii in black pink shoe fits your criteria, as it is a women's black shoe with pink details.\n"
     ]
    }
   ],
   "source": [
    "# Query the engine for black shoes with red details\n",
    "response = query_engine.query(\"I need women's black shoes with red details\")\n",
    "\n",
    "print(\"Chatbot response: \", response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1146d4-72c7-44b4-adea-86f8b0b409bd",
   "metadata": {},
   "source": [
    "# Visualize pulled shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56f1acc4-3e8a-4868-96e1-5ff9e0d911c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display: flex; flex-wrap: wrap; gap: 20px;'>\n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Nike women's transform iii in black pink shoe</p>\n",
       "                    <img src='data/footwear/759.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Fila men's agony black red shoe</p>\n",
       "                    <img src='data/footwear/189.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Fila men's passion black red canvas shoe</p>\n",
       "                    <img src='data/footwear/134.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Red tape black men's semi casual shoe</p>\n",
       "                    <img src='data/footwear/579.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Converse men's chuck taylor big check red black canvas shoe</p>\n",
       "                    <img src='data/footwear/478.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Red tape men's black formal shoe</p>\n",
       "                    <img src='data/footwear/45.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Nike women's double team lite black shoe</p>\n",
       "                    <img src='data/footwear/704.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Red tape men's black casual shoe</p>\n",
       "                    <img src='data/footwear/346.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_nodes_with_images_in_row(response.source_nodes, image_folder_path='../data/footwear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83fcfbb-ba2f-4b02-9c25-505de1344bcb",
   "metadata": {},
   "source": [
    "# Query engine limitations\n",
    "Looking at the results, the chatbot correctly understands the context of **\"women's black shoes with red details\"** and recommends one pair of black shoes with red details.\n",
    "\n",
    "However, while the LLM correctly identifies that black shoes are requested, it fails to pull multiple black shoes with red details, due to the vector query.\n",
    "\n",
    "Looking at the pulled shoes, 8 out of 10 are **men's** shoes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "699b60a6-15e6-4849-9dc4-dbdf24a6170f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display: flex; flex-wrap: wrap; gap: 20px;'>\n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Nike women's transform iii in black pink shoe</p>\n",
       "                    <img src='data/footwear/759.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Fila men's agony black red shoe</p>\n",
       "                    <img src='data/footwear/189.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Fila men's passion black red canvas shoe</p>\n",
       "                    <img src='data/footwear/134.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Red tape black men's semi casual shoe</p>\n",
       "                    <img src='data/footwear/579.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Converse men's chuck taylor big check red black canvas shoe</p>\n",
       "                    <img src='data/footwear/478.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Red tape men's black formal shoe</p>\n",
       "                    <img src='data/footwear/45.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Nike women's double team lite black shoe</p>\n",
       "                    <img src='data/footwear/704.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Red tape men's black casual shoe</p>\n",
       "                    <img src='data/footwear/346.jpg' width='100px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_nodes_with_images_in_row(response.source_nodes, image_folder_path='../data/footwear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ae4fd-11a2-4e4e-97ac-071b0759cea6",
   "metadata": {},
   "source": [
    "# Why did the naive chatbot fail?\n",
    "The naive chatbot struggled with this query because it is designed to vectorize the **entire user query** and match it against the shoes in the vector database.\n",
    "\n",
    "While this approach works well for straightforward searches, like the **\"red shoes\"** we tried earlier, it has limitations for multiple colors like \"**black** shoes with **red** details\":\n",
    "\n",
    "![The LLM correctly identifies that black shoes are requested but it fails to pull multiple black shoes with red details](https://norahsakal.com/assets/images/1_query_engine_output-2fc6cb81cf312156bc459ce11240317d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c18019b-4534-43e9-b58d-e7685f256cd3",
   "metadata": {},
   "source": [
    "# Verify women's black shoes with red details in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb8626-7221-44e2-a60a-8ca412efc03b",
   "metadata": {},
   "source": [
    "Despite that black shoes with red details exist in the dataset, the simple RAG system failed to retrieve them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "04948ebe-a2b2-47c7-be89-498e60fc04cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_title</th>\n",
       "      <th>gender</th>\n",
       "      <th>product_type</th>\n",
       "      <th>color</th>\n",
       "      <th>usage</th>\n",
       "      <th>color_details</th>\n",
       "      <th>heel_height</th>\n",
       "      <th>heel_type</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_id</th>\n",
       "      <th>image</th>\n",
       "      <th>titan_embedding</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>Nike women double team lite black shoes</td>\n",
       "      <td>women</td>\n",
       "      <td>casual shoes</td>\n",
       "      <td>black</td>\n",
       "      <td>casual</td>\n",
       "      <td>[red]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>nike</td>\n",
       "      <td>706</td>\n",
       "      <td>706.jpg</td>\n",
       "      <td>[0.01401766, -0.007690088, 0.004016977, -0.004...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>Puma women saba ballet dc3 black casual shoes</td>\n",
       "      <td>women</td>\n",
       "      <td>casual shoes</td>\n",
       "      <td>black</td>\n",
       "      <td>casual</td>\n",
       "      <td>[red]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170</td>\n",
       "      <td>puma</td>\n",
       "      <td>913</td>\n",
       "      <td>913.jpg</td>\n",
       "      <td>[0.053020123, 0.0035624718, 0.017885217, -0.00...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Puma women black crazy slide flats</td>\n",
       "      <td>women</td>\n",
       "      <td>flats</td>\n",
       "      <td>black</td>\n",
       "      <td>casual</td>\n",
       "      <td>[red]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130</td>\n",
       "      <td>puma</td>\n",
       "      <td>959</td>\n",
       "      <td>959.jpg</td>\n",
       "      <td>[0.026023556, -0.015191399, -0.00014282111, -0...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Catwalk women black heels</td>\n",
       "      <td>women</td>\n",
       "      <td>heels</td>\n",
       "      <td>black</td>\n",
       "      <td>casual</td>\n",
       "      <td>[red]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>stiletto</td>\n",
       "      <td>70</td>\n",
       "      <td>catwalk</td>\n",
       "      <td>997</td>\n",
       "      <td>997.jpg</td>\n",
       "      <td>[0.038116843, 0.0013890459, -0.036084555, 0.00...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>Adidas women court sequence black shoe</td>\n",
       "      <td>women</td>\n",
       "      <td>casual shoes</td>\n",
       "      <td>black</td>\n",
       "      <td>casual</td>\n",
       "      <td>[red]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>adidas</td>\n",
       "      <td>1212</td>\n",
       "      <td>1212.jpg</td>\n",
       "      <td>[0.02072281, -0.00848748, -0.025447942, -0.055...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>Hm women black sandals</td>\n",
       "      <td>women</td>\n",
       "      <td>flats</td>\n",
       "      <td>black</td>\n",
       "      <td>casual</td>\n",
       "      <td>[red]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125</td>\n",
       "      <td>hm</td>\n",
       "      <td>1286</td>\n",
       "      <td>1286.jpg</td>\n",
       "      <td>[-0.0054102736, 0.009834683, -0.015783966, 0.0...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      product_title gender  product_type  \\\n",
       "705         Nike women double team lite black shoes  women  casual shoes   \n",
       "912   Puma women saba ballet dc3 black casual shoes  women  casual shoes   \n",
       "958              Puma women black crazy slide flats  women         flats   \n",
       "996                       Catwalk women black heels  women         heels   \n",
       "1211         Adidas women court sequence black shoe  women  casual shoes   \n",
       "1285                         Hm women black sandals  women         flats   \n",
       "\n",
       "      color   usage color_details  heel_height heel_type  price_usd    brand  \\\n",
       "705   black  casual         [red]          NaN       NaN        150     nike   \n",
       "912   black  casual         [red]          NaN       NaN        170     puma   \n",
       "958   black  casual         [red]          NaN       NaN        130     puma   \n",
       "996   black  casual         [red]          2.0  stiletto         70  catwalk   \n",
       "1211  black  casual         [red]          NaN       NaN         65   adidas   \n",
       "1285  black  casual         [red]          NaN       NaN        125       hm   \n",
       "\n",
       "      product_id     image                                    titan_embedding  \\\n",
       "705          706   706.jpg  [0.01401766, -0.007690088, 0.004016977, -0.004...   \n",
       "912          913   913.jpg  [0.053020123, 0.0035624718, 0.017885217, -0.00...   \n",
       "958          959   959.jpg  [0.026023556, -0.015191399, -0.00014282111, -0...   \n",
       "996          997   997.jpg  [0.038116843, 0.0013890459, -0.036084555, 0.00...   \n",
       "1211        1212  1212.jpg  [0.02072281, -0.00848748, -0.025447942, -0.055...   \n",
       "1285        1286  1286.jpg  [-0.0054102736, 0.009834683, -0.015783966, 0.0...   \n",
       "\n",
       "     token_count  \n",
       "705           11  \n",
       "912           13  \n",
       "958            9  \n",
       "996            7  \n",
       "1211           9  \n",
       "1285           8  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the dataset for women's black shoes with red details\n",
    "black_red_shoe_filter = df_shoes[(df_shoes['gender'] == 'women') &\n",
    "         (df_shoes['color'] == 'black') &\n",
    "         (df_shoes['color_details'].apply(lambda x: 'red' in x))]\n",
    "black_red_shoe_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfad5c0-61b9-43da-8753-fecc67c21457",
   "metadata": {},
   "source": [
    "# Visualize shoes in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "afe51791-2340-4f42-b7eb-02cd5e565e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center;\"><img src=\"data/footwear/706.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/913.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/959.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/997.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/1212.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/1286.jpg\" style=\"width:100px; margin-right:10px;\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "width = 100\n",
    "images_html = \"\"\n",
    "for img_file in black_red_shoe_filter['image']:\n",
    "    img_path = os.path.join(image_data_path, img_file)\n",
    "    # Add each image as an HTML <img> tag\n",
    "    images_html += f'<img src=\"{img_path}\" style=\"width:{width}px; margin-right:10px;\">'\n",
    "# Display all images in a row using HTML\n",
    "display(HTML(f'<div style=\"display: flex; align-items: center;\">{images_html}</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27774f75-66ea-4fd7-9fcd-14c4cc812c3a",
   "metadata": {},
   "source": [
    "# Build an AI agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6384065c-8074-4cb8-9a77-71dc7318a101",
   "metadata": {},
   "source": [
    "## Create vector info\n",
    "We'll start by defining metadata about the vector store we created to allow the AI agent to filter results based on the shoe attributes like:\n",
    "\n",
    "- gender\n",
    "- usage\n",
    "- color\n",
    "- color details\n",
    "- heel heights\n",
    "\n",
    "This metadata will enhance the AI agent's ability to refine queries and pull relevant shoes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e1a623-0714-4887-8812-075fbf918fe5",
   "metadata": {},
   "source": [
    "## Define helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2c79cd1a-4b24-414d-91b6-24f469357660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_options_string(column, is_list_column=False):\n",
    "    # Extract unique values\n",
    "    if is_list_column:\n",
    "        # For list columns, flatten and get unique values\n",
    "        unique_values = set(item for sublist in column.dropna() for item in sublist)\n",
    "    else:\n",
    "        # For non-list columns, get unique values\n",
    "        unique_values = set(column.dropna())\n",
    "\n",
    "    # Sort values for consistency\n",
    "    sorted_values = sorted(unique_values)\n",
    "\n",
    "    # Handle the string formatting\n",
    "    if not sorted_values:\n",
    "        return \"No values available\"\n",
    "    elif len(sorted_values) == 1:\n",
    "        return f\"'{sorted_values[0]}'\"\n",
    "    else:\n",
    "        formatted_values = \", \".join(f\"'{value}'\" for value in sorted_values[:-1])\n",
    "        formatted_string = f\"Either {formatted_values} or '{sorted_values[-1]}'\"\n",
    "        print(formatted_string)\n",
    "        return formatted_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f8ecf-8989-45e4-a26d-7509cd76a5f9",
   "metadata": {},
   "source": [
    "## Create vector store info strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "91c0888f-b162-42a8-ab11-0696029eb19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Either 'beige', 'black', 'blue', 'bronze', 'brown', 'charcoal', 'copper', 'coral', 'cream', 'gold', 'green', 'grey', 'khaki', 'lavender', 'maroon', 'metallic', 'multi', 'mushroom brown', 'mustard', 'navy blue', 'nude', 'off white', 'olive', 'orange', 'peach', 'pink', 'purple', 'red', 'silver', 'tan', 'taupe', 'teal', 'turquoise blue', 'white' or 'yellow'\n",
      "Either 'beige', 'black', 'blue', 'bronze', 'brown', 'cream', 'gold', 'green', 'grey', 'maroon', 'metallic', 'multi', 'navy blue', 'off white', 'olive', 'orange', 'pink', 'purple', 'red', 'silver', 'tan', 'teal', 'white' or 'yellow'\n",
      "Either 'men' or 'women'\n",
      "Either 'boots', 'casual', 'formal', 'semi formal', 'smart casual' or 'sports'\n"
     ]
    }
   ],
   "source": [
    "color_string = generate_options_string(df_shoes['color'])\n",
    "color_details_string = generate_options_string(df_shoes['color_details'], is_list_column=True)\n",
    "gender_string = generate_options_string(df_shoes['gender'])\n",
    "usage_string = generate_options_string(df_shoes['usage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97f5ddf-5961-4674-82c6-58e8ba230cd0",
   "metadata": {},
   "source": [
    "## Create vector store info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3f2cc4e3-dfee-4912-a973-918ec389cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector store information\n",
    "vector_store_info = VectorStoreInfo(\n",
    "    content_info=\"shoes in the shoe store\",\n",
    "    metadata_info=[\n",
    "        MetadataInfo(\n",
    "            name=\"gender\",\n",
    "            type=\"str\",\n",
    "            description=f\"{gender_string}\", # our string for gender\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"usage\",\n",
    "            type=\"str\",\n",
    "            description=f\"{usage_string}\", # our string for usage\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"color\",\n",
    "            type=\"str\",\n",
    "            description=f\"{color_string}\", # our string for color\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"color_details\",\n",
    "            type=\"List[str]\",\n",
    "            description=f\"A list of colors that are in a specified array, filter operator 'in', value has to be List[str] each color being one of: {color_details_string}\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"price\",\n",
    "            type=\"int\",\n",
    "            description=\"The price of the shoes in USD. Must be greater than or equal to 0.\",\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea924c5-f891-4ef5-93ac-86da9b2a75cd",
   "metadata": {},
   "source": [
    "## Create Tools\n",
    "Tools are essential for enabling the AI Agent to interact with the vector store.\n",
    "We'll define two tools:\n",
    "\n",
    "1. **create_metadata_filter:** Generates metadata filters for refining the search query\n",
    "2. **search_footwear_database:** Searches the vector database using the query and optional filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceb7c3c-8c13-4fc6-9234-741b243644a5",
   "metadata": {},
   "source": [
    "# Define agent metadata filter tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c63a6bd-f5d9-4195-8b55-89d0018a46e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tool to create metadata filters\n",
    "def create_metadata_filter(filter_string):\n",
    "    \"\"\"\n",
    "    Creates metadata filter JSON for vector database queries.\n",
    "\n",
    "    Args:\n",
    "        filter_string (str): Query string for generating metadata filters.\n",
    "\n",
    "    Returns:\n",
    "        str: JSON string of filters.\n",
    "    \"\"\"\n",
    "    class CustomRetriever(VectorIndexAutoRetriever):\n",
    "        def __init__(self, vector_index, vector_store_info, **kwargs):\n",
    "            super().__init__(vector_index, vector_store_info, **kwargs)\n",
    "\n",
    "        def _retrieve(self, query, **kwargs):\n",
    "            query_bundle = QueryBundle(query_str=query)\n",
    "            retrieval_spec = self.generate_retrieval_spec(query_bundle)\n",
    "            return retrieval_spec\n",
    "\n",
    "    # Separate LLM for generating a filter\n",
    "    llm_filter = OpenAI_Llama(\n",
    "        temperature=1, # higher temperature than 0 for creativity\n",
    "        model=\"gpt-4o\",\n",
    "        api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "        system_prompt=\"You are a helpful assistant, help the user purchase shoes.\",\n",
    "    )\n",
    "\n",
    "    custom_retriever = CustomRetriever(\n",
    "        vector_index=vector_index,\n",
    "        vector_store_info=vector_store_info,\n",
    "        llm=llm_filter\n",
    "    )\n",
    "\n",
    "    retrieval_spec = custom_retriever._retrieve(filter_string)\n",
    "\n",
    "    filters_dicts = [{'key': f.key, 'value': f.value, 'operator': f.operator.value} for f in retrieval_spec.filters]\n",
    "    return json.dumps(filters_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2600038f-0ed9-4022-a69b-361a9698c540",
   "metadata": {},
   "source": [
    "# Define agent vector database search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d270eab2-d480-4e20-998d-790334d0408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tool to search the footwear vector database\n",
    "def search_footwear_database(query_str, filters_json=None):\n",
    "    \"\"\"\n",
    "    Searches the footwear vector database using a query string and optional filters.\n",
    "\n",
    "    Args:\n",
    "        query_str (str): Query string describing the footwear.\n",
    "        filters_json (Optional[List]): JSON list of metadata filters.\n",
    "\n",
    "    Returns:\n",
    "        list: Search results from the vector database.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate the embedding for the query string\n",
    "    query_embedding = embed_model._get_query_embedding(query_str)\n",
    "\n",
    "    # Deserialize from JSON\n",
    "    if filters_json is None:\n",
    "        metadata_filters = None\n",
    "    else:\n",
    "        metadata_filters = MetadataFilters.from_dicts(filters_json, condition=FilterCondition.AND)\n",
    "\n",
    "\n",
    "    vector_store_query = VectorStoreQuery(\n",
    "        query_str=query_str,\n",
    "        query_embedding=query_embedding,\n",
    "        alpha=0.5,\n",
    "        mode='hybrid',\n",
    "        filters=metadata_filters,\n",
    "        similarity_top_k=10\n",
    "    )\n",
    "\n",
    "    # Execute the query against the vector store\n",
    "    query_result = vector_store.query(vector_store_query)\n",
    "\n",
    "    # Create output without embeddings\n",
    "    nodes_with_scores = []\n",
    "    for index, node in enumerate(query_result.nodes):\n",
    "        score: Optional[float] = None\n",
    "        if query_result.similarities is not None:\n",
    "            score = query_result.similarities[index]\n",
    "        nodes_with_scores.append({\n",
    "            'color': node.metadata['color'],\n",
    "            'text': node.metadata['text'],\n",
    "            'gender': node.metadata['gender'],\n",
    "            'product_type': node.metadata['product_type'],\n",
    "            'product_id': node.metadata['product_id'],\n",
    "            'usage': node.metadata['usage'],\n",
    "            'price': node.metadata['price'],\n",
    "            'brand': node.metadata['brand'],\n",
    "            'heel_height': node.metadata.get('heel_height'),  # Add heel_height if present\n",
    "            'heel_type': node.metadata.get('heel_type'),  # Add heel_type if present\n",
    "            'similarity_score': score\n",
    "        })\n",
    "\n",
    "    return nodes_with_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa775b-5b11-4386-8e90-428b921ce8bf",
   "metadata": {},
   "source": [
    "## Define agent tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cf75f546-b159-43d9-8c6c-112eaa5382d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_metadata_filters_tool = FunctionTool.from_defaults(\n",
    "    name=\"create_metadata_filter\",\n",
    "    fn=create_metadata_filter\n",
    ")\n",
    "\n",
    "query_vector_database_tool = FunctionTool.from_defaults(\n",
    "    name=\"search_footwear_database\",\n",
    "    fn=search_footwear_database\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5632768-e18b-4e41-802f-993b11250dec",
   "metadata": {},
   "source": [
    "# Create AI Agent\n",
    "We'll now define an AI Agent capable of reasoning over the data, generating filters, and performing refined searches to address customer queries more effectively.\n",
    "\n",
    "## Create the agent worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "41d2123f-5981-485f-a415-2fecfa71e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent worker\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [\n",
    "        create_metadata_filters_tool,\n",
    "        query_vector_database_tool,\n",
    "    ],\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    system_prompt=\"\"\"\\\n",
    "You are an agent designed to answer customers looking for shoes.\\\n",
    "Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\n",
    "Drive sales and always feel free to ask a user for more information.\\\n",
    "\n",
    "- Always consider if filters are needed based on the user's query.\n",
    "- Use the tools provided to answer questions; do not rely on prior knowledge.\n",
    "- Always feel free to ask a user for more information.\n",
    "\n",
    "**Example 1:**\n",
    "\n",
    "User Query: \"Hi! I'm going to a party and I'm looking for red women's shoes. Thank you!\"\n",
    "\n",
    "Agent Actions:\n",
    "\n",
    "1. Determine what query string to use for filters e.g. \"red woman's shoes\"\n",
    "2. Call:\n",
    "   filters_dicts = create_metadata_filter_string(\"red woman's shoes\")\n",
    "3. Call:\n",
    "   results = search_footwear_database(query_str='shoes', filters_json=filters_dicts)\n",
    "\n",
    "**Example 2:**\n",
    "\n",
    "User Query: \"Hi! I'm going to a meeting and I'm looking for formal women's shoes. Thank you!\"\n",
    "\n",
    "Agent Actions:\n",
    "\n",
    "1. Determine what query string to use for filters e.g. \"formal woman's shoes\"\n",
    "2. Call:\n",
    "   filters_dicts = create_metadata_filter_string(\"formal woman's shoes\")\n",
    "3. Call:\n",
    "   results = search_footwear_database(query_str='shoes', filters_json=filters_dicts)\n",
    "\n",
    "**Example 3:**\n",
    "\n",
    "User Query: \"I'm looking for shoes\"\n",
    "\n",
    "Agent Actions:\n",
    "\n",
    "1. Ask for more information\n",
    "\n",
    "**Example 4:**\n",
    "\n",
    "User Query: \"I'm looking for stable heels\"\n",
    "\n",
    "Agent Actions:\n",
    "\n",
    "1. Determine what query string to use for filters e.g. \"women's heels\"\n",
    "2. Call:\n",
    "   filters_dicts = create_metadata_filter_string(\"women's heels\")\n",
    "3. Call:\n",
    "   results = search_footwear_database(query_str='wedges', filters_json=filters_dicts)\n",
    "\n",
    "Remember to follow these instructions carefully.\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d30619-d19a-40bf-986c-2af86889524d",
   "metadata": {},
   "source": [
    "# Create the AI agent runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "87d4ae4c-a11a-4bb3-adc2-3d33522604db",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e545b4fe-a6e4-4930-8e77-961cede8adaa",
   "metadata": {},
   "source": [
    "# Test AI agent\n",
    "Let's test the AI agent by asking for \"women's black shoes with red details\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "19673824-88e4-4f99-a949-533a8cefe7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: I need women's black shoes with red details\n",
      "=== Calling Function ===\n",
      "Calling function: create_metadata_filter with args: {\"filter_string\": \"women's black shoes with red details\"}\n",
      "=== Function Output ===\n",
      "[{\"key\": \"gender\", \"value\": \"women\", \"operator\": \"==\"}, {\"key\": \"color\", \"value\": \"black\", \"operator\": \"==\"}, {\"key\": \"color_details\", \"value\": [\"red\"], \"operator\": \"in\"}]\n",
      "=== Calling Function ===\n",
      "Calling function: search_footwear_database with args: {\"query_str\": \"shoes\", \"filters_json\": [{\"key\": \"gender\", \"value\": \"women\", \"operator\": \"==\"}, {\"key\": \"color\", \"value\": \"black\", \"operator\": \"==\"}, {\"key\": \"color_details\", \"value\": [\"red\"], \"operator\": \"in\"}]}\n",
      "=== Function Output ===\n",
      "[{'color': 'black', 'text': 'Puma women saba ballet dc3 black casual shoes', 'gender': 'women', 'product_type': 'casual shoes', 'product_id': 913, 'usage': 'casual', 'price': 170, 'brand': 'puma', 'heel_height': None, 'heel_type': None, 'similarity_score': 1.69973636}, {'color': 'black', 'text': 'Nike women double team lite black shoes', 'gender': 'women', 'product_type': 'casual shoes', 'product_id': 706, 'usage': 'casual', 'price': 150, 'brand': 'nike', 'heel_height': None, 'heel_type': None, 'similarity_score': 1.69866252}, {'color': 'black', 'text': 'Hm women black sandals', 'gender': 'women', 'product_type': 'flats', 'product_id': 1286, 'usage': 'casual', 'price': 125, 'brand': 'hm', 'heel_height': None, 'heel_type': None, 'similarity_score': 1.22095072}, {'color': 'black', 'text': 'Catwalk women black heels', 'gender': 'women', 'product_type': 'heels', 'product_id': 997, 'usage': 'casual', 'price': 70, 'brand': 'catwalk', 'heel_height': 2.0, 'heel_type': 'stiletto', 'similarity_score': 1.1970259}, {'color': 'black', 'text': 'Adidas women court sequence black shoe', 'gender': 'women', 'product_type': 'casual shoes', 'product_id': 1212, 'usage': 'casual', 'price': 65, 'brand': 'adidas', 'heel_height': None, 'heel_type': None, 'similarity_score': 1.18892908}, {'color': 'black', 'text': 'Puma women black crazy slide flats', 'gender': 'women', 'product_type': 'flats', 'product_id': 959, 'usage': 'casual', 'price': 130, 'brand': 'puma', 'heel_height': None, 'heel_type': None, 'similarity_score': 1.16182387}]\n",
      "=== LLM Response ===\n",
      "Here are some women's black shoes with red details that you might like:\n",
      "\n",
      "1. **Puma Women Saba Ballet DC3 Black Casual Shoes**\n",
      "   - Price: $170\n",
      "   - Brand: Puma\n",
      "   - Type: Casual Shoes\n",
      "\n",
      "2. **Nike Women Double Team Lite Black Shoes**\n",
      "   - Price: $150\n",
      "   - Brand: Nike\n",
      "   - Type: Casual Shoes\n",
      "\n",
      "3. **H&M Women Black Sandals**\n",
      "   - Price: $125\n",
      "   - Brand: H&M\n",
      "   - Type: Flats\n",
      "\n",
      "4. **Catwalk Women Black Heels**\n",
      "   - Price: $70\n",
      "   - Brand: Catwalk\n",
      "   - Type: Heels\n",
      "   - Heel Height: 2.0 inches\n",
      "   - Heel Type: Stiletto\n",
      "\n",
      "5. **Adidas Women Court Sequence Black Shoe**\n",
      "   - Price: $65\n",
      "   - Brand: Adidas\n",
      "   - Type: Casual Shoes\n",
      "\n",
      "6. **Puma Women Black Crazy Slide Flats**\n",
      "   - Price: $130\n",
      "   - Brand: Puma\n",
      "   - Type: Flats\n",
      "\n",
      "Let me know if you need more information on any of these options!\n"
     ]
    }
   ],
   "source": [
    "# Test the agent\n",
    "agent_response = agent.chat(\"I need women's black shoes with red details\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14943a7-7169-48ec-a0b5-ac0cf9c25d3a",
   "metadata": {},
   "source": [
    "# Interpreting the Query\n",
    "Unlike a naive query engine, which vectorizes the full user query, the AI agent approaches the request by changing the query and add a custom filter.\n",
    "\n",
    "For the query \"I need women's black shoes with red details\", the agent decides to not vectorize the entire customer query. \n",
    "\n",
    "Instead, the agent vectorizes just the query **shoes** and then creates a filter for the condition **women's black shoes with red** details and then recommends 6 different shoes:\n",
    "\n",
    "![The AI agent looks through the retrieved vector database results and provide a response with recommended shoes](https://norahsakal.com/assets/images/2_agent_response-035170dfb641aec09c729ddb781c845f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b5fd86-52c4-4488-a1e6-834e92a30cf9",
   "metadata": {},
   "source": [
    "# Visualize the AI agent's recommendations\n",
    "\n",
    "Let's go ahead create a helper function that visualizes the AI agent's recommended shoes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c5e3d276-b546-49f2-a123-29e58091e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_agent_response(agent_response, image_folder_path=None, img_width=150, threshold=98):\n",
    "    \"\"\"\n",
    "    Visualizes products from agent response if they match (fuzzily) names in an unstructured string.\n",
    "\n",
    "    Args:\n",
    "    - agent_response: Agent response.\n",
    "    - image_folder: Path to the folder containing product images.\n",
    "    - img_width: Width of the product images in the visualization.\n",
    "    - threshold: Minimum similarity score for fuzzy matching.\n",
    "\n",
    "    Returns:\n",
    "    - None: Displays the visualization directly in the notebook.\n",
    "    \"\"\"\n",
    "    if image_folder_path is None:\n",
    "        raise ValueError(\"You must specify an image folder path.\")\n",
    "\n",
    "    # Extract product names from raw output and make them lowercase\n",
    "    products = [product['text'].lower() for product in agent_response.sources[1].raw_output]\n",
    "\n",
    "    # Prepare HTML content for visualization\n",
    "    html_content = \"<div style='display: flex; flex-wrap: wrap; gap: 20px;'>\"\n",
    "\n",
    "    # Loop through the products and match with unstructured string\n",
    "    for product in agent_response.sources[1].raw_output:\n",
    "        product_name = product['text'].lower()\n",
    "\n",
    "        # Perform fuzzy matching\n",
    "        match = process.extractOne(product_name, [agent_response.response.lower()], scorer=fuzz.partial_ratio)\n",
    "        if match and match[1] > threshold:  # If a match is found and meets the threshold\n",
    "            # Generate image path based on product_id\n",
    "            image_path = os.path.join(image_folder_path, f\"{product['product_id']}.jpg\")\n",
    "\n",
    "            # Append product info and image to HTML content\n",
    "            html_content += f\"\"\"\n",
    "                <div style=\"text-align: center;\">\n",
    "                    <p>{product['text']}</p>\n",
    "                    <img src='{image_path}' width='{img_width}px' style=\"padding: 5px;\"/>\n",
    "                </div>\n",
    "            \"\"\"\n",
    "\n",
    "    # Close the main div\n",
    "    html_content += \"</div>\"\n",
    "\n",
    "    # Display the content as HTML\n",
    "    display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879da8c0-0b74-41fd-a7ff-e4ba4768e8cd",
   "metadata": {},
   "source": [
    "## Visulize pulled shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "52453967-fb35-485c-904e-dbdb98dd7230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='display: flex; flex-wrap: wrap; gap: 20px;'>\n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Puma women saba ballet dc3 black casual shoes</p>\n",
       "                    <img src='data/footwear/913.jpg' width='150px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Nike women double team lite black shoes</p>\n",
       "                    <img src='data/footwear/706.jpg' width='150px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Catwalk women black heels</p>\n",
       "                    <img src='data/footwear/997.jpg' width='150px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Adidas women court sequence black shoe</p>\n",
       "                    <img src='data/footwear/1212.jpg' width='150px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            \n",
       "                <div style=\"text-align: center;\">\n",
       "                    <p>Puma women black crazy slide flats</p>\n",
       "                    <img src='data/footwear/959.jpg' width='150px' style=\"padding: 5px;\"/>\n",
       "                </div>\n",
       "            </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call the function\n",
    "visualize_agent_response(agent_response, image_folder_path=image_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0462c5bc-2b11-4234-a0da-60bca904d04a",
   "metadata": {},
   "source": [
    "# Compare AI agent recommendations with available shoes\n",
    "Looking back at when we filtered our shoe directory for black women's shoes with red details, we received these **6 pair of shoes**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "671aee5a-429a-48a7-8cde-df75dfca749d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; align-items: center;\"><img src=\"data/footwear/706.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/913.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/959.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/997.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/1212.jpg\" style=\"width:100px; margin-right:10px;\"><img src=\"data/footwear/1286.jpg\" style=\"width:100px; margin-right:10px;\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verify the dataset for women's black shoes with red details\n",
    "black_red_shoe_filter = df_shoes[(df_shoes['gender'] == 'women') &\n",
    "         (df_shoes['color'] == 'black') &\n",
    "         (df_shoes['color_details'].apply(lambda x: 'red' in x))]\n",
    "\n",
    "width = 100\n",
    "images_html = \"\"\n",
    "for img_file in black_red_shoe_filter['image']:\n",
    "    img_path = os.path.join(image_data_path, img_file)\n",
    "    # Add each image as an HTML <img> tag\n",
    "    images_html += f'<img src=\"{img_path}\" style=\"width:{width}px; margin-right:10px;\">'\n",
    "# Display all images in a row using HTML\n",
    "display(HTML(f'<div style=\"display: flex; align-items: center;\">{images_html}</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9d18be-32ec-4e75-9d6e-8b10f1440520",
   "metadata": {},
   "source": [
    "The AI agent reply includes all of these 6 pair of shoes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "80b86bf3-cf5d-436d-8a82-c9ec389254af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some women's black shoes with red details that you might like:\n",
      "\n",
      "1. **Puma Women Saba Ballet DC3 Black Casual Shoes**\n",
      "   - Price: $170\n",
      "   - Brand: Puma\n",
      "   - Type: Casual Shoes\n",
      "\n",
      "2. **Nike Women Double Team Lite Black Shoes**\n",
      "   - Price: $150\n",
      "   - Brand: Nike\n",
      "   - Type: Casual Shoes\n",
      "\n",
      "3. **H&M Women Black Sandals**\n",
      "   - Price: $125\n",
      "   - Brand: H&M\n",
      "   - Type: Flats\n",
      "\n",
      "4. **Catwalk Women Black Heels**\n",
      "   - Price: $70\n",
      "   - Brand: Catwalk\n",
      "   - Type: Heels\n",
      "   - Heel Height: 2.0 inches\n",
      "   - Heel Type: Stiletto\n",
      "\n",
      "5. **Adidas Women Court Sequence Black Shoe**\n",
      "   - Price: $65\n",
      "   - Brand: Adidas\n",
      "   - Type: Casual Shoes\n",
      "\n",
      "6. **Puma Women Black Crazy Slide Flats**\n",
      "   - Price: $130\n",
      "   - Brand: Puma\n",
      "   - Type: Flats\n",
      "\n",
      "Let me know if you need more information on any of these options!\n"
     ]
    }
   ],
   "source": [
    "print(agent_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dee3cb6-9656-44ec-899f-ad3cd71b7470",
   "metadata": {},
   "source": [
    "# How did the AI agent succeed?\n",
    "- Understands multiple color request\n",
    "- Applies filters to return all matches, not just the first found\n",
    "- Leverages metadata (gender and color_details) to ensure accurate results\n",
    "\n",
    "## Key takeaways\n",
    "**Naive chatbot limitation**\n",
    "- Finds limited or no results due to lack of multiple color filtering\n",
    "\n",
    "**AI agent advantages**\n",
    "- Accurately applies multiple color filters\n",
    "- Shows all products that fit the user's request\n",
    "- Enhances the shopping experience with full, accurate results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc76f7e-5e9d-4503-a730-fcc60be609d1",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "When users specify multiple color requirements like black shoes with red details, naive chatbots fail to apply proper filters and return only partial matches.\n",
    "\n",
    "AI agents, on the other hand, use metadata filtering and reasoning to find all suitable options, improving both accuracy and user satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de6468c-aa2d-47a0-9b41-34f8f304d9a2",
   "metadata": {},
   "source": [
    "# Want to go deeper?\n",
    "\n",
    "This Notebook is part of a free mini-course where we'll dig deeper into the mechanics behind building this AI agent.\n",
    "\n",
    "## [Enroll for free ↗](https://norahsakal.gumroad.com/l/mini-course-1)\n",
    "\n",
    "[![Mini-course](https://d1fiydes8a4qgo.cloudfront.net/mini-courses/mini-course-1/social_media_cover.png)](https://norahsakal.com/courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b9056b-3b69-4d74-80ee-c455c0fc8932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c044e0-d893-4218-8f9d-558c8075d91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05c500b-a5d9-4f4e-8202-e39c32a45518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
